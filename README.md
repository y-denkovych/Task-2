Task 2.1
The strategy that was provided through https://quantpedia.com/strategies/value-book-to-market-factor/ link, was built and backtested through Quantconnect website. The resulted backtest was Extracted, Transformed, and Loaded into PostgreSQL database for future reference, data upkeeping, and ability to analyse and plot via 3rd party Software. Additionally it could be useful as a part of larger pipeline, where other data streams into the database such as: sentiment/news analysis, other backtests that were done on different datasets, markets, and platforms. Overall, storing backtest data into a relational database might be beneficial. Code for ETL process can be found in ETL.ipynb file. Backtest data for the base algorithm can be found in Base.json. The code for algorithm can be found under Base.py
When it comes to assessing the algorithm, regular “front page” metrics found on Quantconnect do a great job, lets focus on several and figure out what it means for our model. Its important to note that backtest results stop at ~ beginning of 2011 due to free-tier limitation of 10000 orders.
Net Profit: For our model Net Profit totalled 552.172%, this value tells us the profit earned by an investment after deducting all expenses and losses. So, 552% would mean that we earned 552% of the initial investment amount over the course of backtest. This metric is probably the most focused and beloved by all as it shows how profitable the model was, taking into account all losses incurred and can serve as an important metric. Although, it does not take into account risk which despite great net profit might be too risky for some investors. Following metrics will help us understand how risky our model is:
Sharpe Ratio: for our model Sharpe ratio equalled 1.097. This means that model has generated 1.097 units of excess return for each unit of risk taken, thus, model has returned slightly more returns for the level of risk taken. 1.097 is not a bad value but could use some improvement. This metric is important for us to use since it gives us an idea of returns that are adjusted for the risk taken. Important to note, that Sharpe ratio assumes that returns follow a normal distribution, which may not always be the case.
Alpha: for our model Alpha was equal to 0.134. This means that our portfolio has outperformed benchmark by 0.134% over the course of a backtest, after adjusting for the risk taken. This is a good metric for us to use as it gives us an idea of our returns when adjusted for the risk. 
Beta: for our model Beta equals to -0.104. This means that our portfolio has negative correlation with the market, thus, moving in opposite direction of the market. This is great as we can expect portfolio to perform well when market is in a downturn. 
Drawdown: in our model drawdown was equal to 30.1%. This metric means that portfolio experienced a maximum decline of 30.1% from its peak value during the backtesting period. This is an important metric as it provides us with the idea of “worst-case” scenario that portfolio has experienced. 
The Treynor ratio: for our model we have -1.267. This metric means that portfolio returned -1.267 times the risk-free rate adjusted for its beta. Portfolio has severely underperformed the risk-free rate when adjusted for portfolio’s systemic risk. Negative value suggests that investment performed worse than risk free instrument. Following metrics will help us understand the relationship of wins/losses in our model which will help us understand how our strategy performed.
Profit-Loss ratio: our model acquired profit-loss ratio of 1.86. This means that portfolio won $1.86 for every dollar lost in losing trades. This is great record for our model.
Average Win / Average Loss: for our model its 0.14 and -0.07 respectively, thus, on our average win we earn a profit of 0.14%, and on a loss trade we lose -0.07%. This metric highlights that we have a favourable risk-reward ratio and potential gains are larger than potential losses. 
Loss Rate / Win Rate: our model has 42% and 58% respectively, mean that 42% and 58% of our trades were losing and winning ones respectively, this is a good value and useful metric for us, but its important to keep in mind that it doesn’t take into account the size and frequency of trades, so theoretically one can have high win rate but still lose money. Gladly, so far model that we have shows good win rate and good profitability on wins.
Expectancy: it is the overall profitability of a trading system that factors in both the win rate and the average win size of the wins and losses. Our model has expectancy of 0.648, which means that each trade has a positive expected outcome of 0.648% of the initial investment. Important to note that it doesn’t take into account risk and transaction costs. 
Portfolio turnover: it refers to the amount of buying and selling of assets within a portfolio over a duration of backtest, in our case it is 0.48%, thus, the model replaced 0.48% of its holdings during the test. This is a relatively low value, which means that portfolio is not actively managed and despite the fact that we avoid high transaction costs, we may miss out on market opportunities. This can be increased via more frequent rebalancing periods.

Task 2.2

Task 2.2 was approached the following way: 4 algorithms per stop-loss were created, one with each rebalancing period (Yearly, Quarters, Monthly, Weekly). Totalling 12 algorithms that were each passed through an ETL process, where they were loaded into a database, and appended into a singular dataframe for ease of comparison and further use such as machine learning, part of an automated backtesting report, and general clarity. File with a dataframe and ETL process for them is: “Task 2.2.ipynb”, file with the ETL prototyping can be found under “ETLBase”, file with the ETL function is “ETLfunction”, file with a database password was omitted, Initial provided code can be found under “Base.py”. Each json file was saved under corresponding name and code for each one of them was saved under the same name in a Python file. 
It is important to note that due to limitation of a free-tier account, only up 10000 orders were allowed to pass through, thus, limiting the historical data severely for algorithms that relied on more active rebalancing such as Weekly and Monthly trading, thus, rendering data hardly comparable with each other especially for metric such as Net Profit, which is evident by considerably higher Net Profit for Yearly algorithms. Additionally, Yearly and Quarters algorithms produce generally better results in Average Win/Loss, Loss/Win rate. SD60d and 2SD120d Quarters algorithms have a higher Alpha and lower Beta, higher PSR, and considerably higher Compounding Annual Return, higher Sharpe Ration, despite lower Treynor ratio it is probable to conclude that they are safer and produce a better return on investment, despite equal Drawdown. Although, it is important to keep in mind that if both Quarters and Yearly algorithms are compared over the same time period then results could be different, but with the data available they show better performance. 
